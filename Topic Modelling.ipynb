{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281cad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "# import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b6e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b64e5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sent_skytrax.csv\", index_col = 0)\n",
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d8a660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_review_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>body</th>\n",
       "      <th>Seat Type</th>\n",
       "      <th>Aircraft Type</th>\n",
       "      <th>Seat Layout</th>\n",
       "      <th>Date Flown</th>\n",
       "      <th>...</th>\n",
       "      <th>Sitting Comfort</th>\n",
       "      <th>Seat/bed Width</th>\n",
       "      <th>Seat/bed Length</th>\n",
       "      <th>Seat Privacy</th>\n",
       "      <th>cleaned_body</th>\n",
       "      <th>scores</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neu_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>compound_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>\"seat was not comfortable\"</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>With their newer A320 aircraft leg room is awf...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>A320</td>\n",
       "      <td>3x3</td>\n",
       "      <td>July 2019</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>newer aircraft leg room awful seat comfortable...</td>\n",
       "      <td>{'neg': 0.139, 'neu': 0.604, 'pos': 0.256, 'co...</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.3626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>\"Check in was easy\"</td>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Check in was easy and boarding I was in zone o...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>A320</td>\n",
       "      <td>3x3</td>\n",
       "      <td>April 2019</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>check easy boarding zone think paid check kg l...</td>\n",
       "      <td>{'neg': 0.068, 'neu': 0.705, 'pos': 0.227, 'co...</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.7430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>\"A solid experience\"</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Australia</td>\n",
       "      <td>A solid experience from start to finish, espec...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>A320</td>\n",
       "      <td>3x3</td>\n",
       "      <td>March 2019</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>solid experience start finish especially given...</td>\n",
       "      <td>{'neg': 0.051, 'neu': 0.777, 'pos': 0.172, 'co...</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.8979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>\"my 4yr old and I allocated different seats\"</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>Australia</td>\n",
       "      <td>I discovered upon boarding that my four-year-o...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>A330-300</td>\n",
       "      <td>3x3x3</td>\n",
       "      <td>January 2018</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discovered upon boarding four year old allocat...</td>\n",
       "      <td>{'neg': 0.161, 'neu': 0.726, 'pos': 0.113, 'co...</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.161</td>\n",
       "      <td>-0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>\"space between was relatively good\"</td>\n",
       "      <td>2017-08-24</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>I got 14A seat, near emergency exit door. So t...</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>A320</td>\n",
       "      <td>3x3</td>\n",
       "      <td>August 2017</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got seat near emergency exit different standar...</td>\n",
       "      <td>{'neg': 0.157, 'neu': 0.66, 'pos': 0.183, 'com...</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_review_count  rating                                         title  \\\n",
       "0                  0.0     0.3                    \"seat was not comfortable\"   \n",
       "1                  0.0     0.6                           \"Check in was easy\"   \n",
       "2                  5.0     0.7                          \"A solid experience\"   \n",
       "3                  0.0     0.1  \"my 4yr old and I allocated different seats\"   \n",
       "4                  1.0     0.7           \"space between was relatively good\"   \n",
       "\n",
       "         date   location                                               body  \\\n",
       "0  2019-07-22   Malaysia  With their newer A320 aircraft leg room is awf...   \n",
       "1  2019-04-06  Australia  Check in was easy and boarding I was in zone o...   \n",
       "2  2019-04-01  Australia  A solid experience from start to finish, espec...   \n",
       "3  2018-01-14  Australia  I discovered upon boarding that my four-year-o...   \n",
       "4  2017-08-24  Indonesia  I got 14A seat, near emergency exit door. So t...   \n",
       "\n",
       "       Seat Type Aircraft Type Seat Layout    Date Flown  ... Sitting Comfort  \\\n",
       "0  Economy Class          A320         3x3     July 2019  ...             NaN   \n",
       "1  Economy Class          A320         3x3    April 2019  ...             NaN   \n",
       "2  Economy Class          A320         3x3    March 2019  ...             NaN   \n",
       "3  Economy Class      A330-300       3x3x3  January 2018  ...             NaN   \n",
       "4  Economy Class          A320         3x3   August 2017  ...             NaN   \n",
       "\n",
       "   Seat/bed Width  Seat/bed Length  Seat Privacy  \\\n",
       "0             NaN              NaN           NaN   \n",
       "1             NaN              NaN           NaN   \n",
       "2             NaN              NaN           NaN   \n",
       "3             NaN              NaN           NaN   \n",
       "4             NaN              NaN           NaN   \n",
       "\n",
       "                                        cleaned_body  \\\n",
       "0  newer aircraft leg room awful seat comfortable...   \n",
       "1  check easy boarding zone think paid check kg l...   \n",
       "2  solid experience start finish especially given...   \n",
       "3  discovered upon boarding four year old allocat...   \n",
       "4  got seat near emergency exit different standar...   \n",
       "\n",
       "                                              scores pos_score neu_score  \\\n",
       "0  {'neg': 0.139, 'neu': 0.604, 'pos': 0.256, 'co...     0.256     0.604   \n",
       "1  {'neg': 0.068, 'neu': 0.705, 'pos': 0.227, 'co...     0.227     0.705   \n",
       "2  {'neg': 0.051, 'neu': 0.777, 'pos': 0.172, 'co...     0.172     0.777   \n",
       "3  {'neg': 0.161, 'neu': 0.726, 'pos': 0.113, 'co...     0.113     0.726   \n",
       "4  {'neg': 0.157, 'neu': 0.66, 'pos': 0.183, 'com...     0.183     0.660   \n",
       "\n",
       "  neg_score  compound_score  \n",
       "0     0.139          0.3626  \n",
       "1     0.068          0.7430  \n",
       "2     0.051          0.8979  \n",
       "3     0.161         -0.5267  \n",
       "4     0.157          0.2960  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f51f7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [r for r in df.cleaned_body.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b219af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0099d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['newer', 'aircraft', 'leg', 'room', 'awful', 'seat', 'comfortable', 'seat', 'maximization', 'mean', 'gave', 'away', 'even', 'little', 'comfort', 'passenger']]\n"
     ]
    }
   ],
   "source": [
    "#tokenize the phrases\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "reviews_words = list(sent_to_words(reviews))\n",
    "\n",
    "print(reviews_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfadcd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seat can be considered as a stopword\n",
    "reviews_words = [[i for i in sentence if i != \"seat\"] for sentence in reviews_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b4a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbd7c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(reviews_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[reviews_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c400edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af834a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['new', 'aircraft', 'leg', 'room', 'awful', 'comfortable', 'maximization', 'mean', 'give', 'away', 'even', 'little', 'comfort', 'passenger']]\n"
     ]
    }
   ],
   "source": [
    "#NOTE: stopwords were already removed in another phase of the data analysis, so now it is not necessary\n",
    "# Form Bigrams\n",
    "reviews_bigr = make_bigrams(reviews_words)\n",
    "\n",
    "## NOTE: we choose bigrams but trigrams could be tested too\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "reviews_lem = lemmatization(reviews_bigr, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(reviews_lem[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90baa10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1)]]\n"
     ]
    }
   ],
   "source": [
    "## Create the Dictionary and Corpus needed for Topic Modeling\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(reviews_lem)\n",
    "\n",
    "# Create Corpus\n",
    "texts = reviews_lem\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77bada4",
   "metadata": {},
   "source": [
    "Corpus maps each phrase in (word_id, word_frequency)\n",
    "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "317eca92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aircraft'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fad17bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('aircraft', 1),\n",
       "  ('away', 1),\n",
       "  ('awful', 1),\n",
       "  ('comfort', 1),\n",
       "  ('comfortable', 1),\n",
       "  ('even', 1),\n",
       "  ('give', 1),\n",
       "  ('leg', 1),\n",
       "  ('little', 1),\n",
       "  ('maximization', 1),\n",
       "  ('mean', 1),\n",
       "  ('new', 1),\n",
       "  ('passenger', 1),\n",
       "  ('room', 1)]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)  for the first review!\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec1510",
   "metadata": {},
   "source": [
    "# Build the topic modeling - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52116477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0e8e1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.098*\"still\" + 0.069*\"personal\" + 0.054*\"plenty\" + 0.038*\"huge\" + '\n",
      "  '0.031*\"comfy\" + 0.029*\"monitor\" + 0.029*\"leather\" + 0.027*\"line\" + '\n",
      "  '0.026*\"real\" + 0.026*\"main\"'),\n",
      " (1,\n",
      "  '0.071*\"ticket\" + 0.067*\"family\" + 0.065*\"happy\" + 0.062*\"squeeze\" + '\n",
      "  '0.054*\"actually\" + 0.047*\"believe\" + 0.034*\"kid\" + 0.033*\"plan\" + '\n",
      "  '0.030*\"slim\" + 0.029*\"emergency\"'),\n",
      " (2,\n",
      "  '0.082*\"flight\" + 0.052*\"economy\" + 0.043*\"good\" + 0.041*\"fly\" + '\n",
      "  '0.034*\"airline\" + 0.033*\"comfortable\" + 0.024*\"well\" + 0.023*\"hour\" + '\n",
      "  '0.022*\"legroom\" + 0.022*\"bad\"'),\n",
      " (3,\n",
      "  '0.046*\"view\" + 0.046*\"thin\" + 0.045*\"become\" + 0.044*\"hr\" + '\n",
      "  '0.040*\"additional\" + 0.038*\"unfortunately\" + 0.038*\"regular\" + '\n",
      "  '0.032*\"light\" + 0.031*\"amount\" + 0.031*\"snack\"'),\n",
      " (4,\n",
      "  '0.414*\"class\" + 0.221*\"business\" + 0.046*\"access\" + 0.040*\"turn\" + '\n",
      "  '0.025*\"similar\" + 0.023*\"remote\" + 0.020*\"touchscreen\" + 0.019*\"direct\" + '\n",
      "  '0.006*\"responsive\" + 0.003*\"suite\"'),\n",
      " (5,\n",
      "  '0.165*\"extremely\" + 0.094*\"cm\" + 0.053*\"stuff\" + 0.045*\"clear\" + '\n",
      "  '0.044*\"individual\" + 0.041*\"reason\" + 0.037*\"speak\" + 0.032*\"truly\" + '\n",
      "  '0.032*\"true\" + 0.028*\"positive\"'),\n",
      " (6,\n",
      "  '0.054*\"average\" + 0.048*\"design\" + 0.047*\"forward\" + 0.039*\"fit\" + '\n",
      "  '0.039*\"head\" + 0.035*\"size\" + 0.035*\"tray\" + 0.032*\"rather\" + '\n",
      "  '0.030*\"pocket\" + 0.027*\"route\"'),\n",
      " (7,\n",
      "  '0.043*\"leg\" + 0.041*\"recline\" + 0.034*\"front\" + 0.032*\"get\" + 0.031*\"room\" '\n",
      "  '+ 0.029*\"back\" + 0.027*\"row\" + 0.025*\"space\" + 0.020*\"even\" + '\n",
      "  '0.020*\"screen\"'),\n",
      " (8,\n",
      "  '0.052*\"time\" + 0.051*\"service\" + 0.041*\"cabin\" + 0.040*\"flight\" + '\n",
      "  '0.038*\"food\" + 0.029*\"crew\" + 0.029*\"travel\" + 0.024*\"never\" + 0.022*\"meal\" '\n",
      "  '+ 0.022*\"offer\"'),\n",
      " (9,\n",
      "  '0.090*\"excellent\" + 0.090*\"close\" + 0.069*\"especially\" + 0.044*\"boarding\" + '\n",
      "  '0.042*\"type\" + 0.040*\"other\" + 0.040*\"end\" + 0.040*\"together\" + '\n",
      "  '0.040*\"elbow\" + 0.033*\"course\"'),\n",
      " (10,\n",
      "  '0.124*\"terrible\" + 0.104*\"tight\" + 0.081*\"allow\" + 0.077*\"second\" + '\n",
      "  '0.054*\"literally\" + 0.034*\"emergency_exit\" + 0.034*\"complaint\" + '\n",
      "  '0.033*\"allocate\" + 0.033*\"thank\" + 0.029*\"cut\"'),\n",
      " (11,\n",
      "  '0.108*\"movie\" + 0.068*\"storage\" + 0.067*\"entertainment_system\" + '\n",
      "  '0.055*\"pain\" + 0.048*\"overhead\" + 0.046*\"definitely\" + 0.044*\"guy\" + '\n",
      "  '0.044*\"quality\" + 0.042*\"plug\" + 0.036*\"manage\"'),\n",
      " (12,\n",
      "  '0.326*\"pitch\" + 0.076*\"trolley\" + 0.070*\"sardine\" + 0.029*\"regional\" + '\n",
      "  '0.022*\"interior\" + 0.000*\"tin\" + 0.000*\"touch\" + 0.000*\"open\" + '\n",
      "  '0.000*\"tonic\" + 0.000*\"emirate\"'),\n",
      " (13,\n",
      "  '0.078*\"haul\" + 0.059*\"bother\" + 0.048*\"time\" + 0.043*\"short\" + '\n",
      "  '0.041*\"distance\" + 0.031*\"average\" + 0.030*\"melbourne\" + 0.027*\"tv\" + '\n",
      "  '0.025*\"bit\" + 0.025*\"long\"'),\n",
      " (14,\n",
      "  '0.273*\"air\" + 0.065*\"stand\" + 0.062*\"cheap\" + 0.047*\"probably\" + '\n",
      "  '0.034*\"date\" + 0.030*\"fare\" + 0.028*\"wall\" + 0.026*\"idea\" + 0.022*\"total\" + '\n",
      "  '0.018*\"sandwich\"'),\n",
      " (15,\n",
      "  '0.113*\"board\" + 0.070*\"review\" + 0.054*\"read\" + 0.050*\"hand\" + '\n",
      "  '0.049*\"understand\" + 0.049*\"lose\" + 0.034*\"forget\" + 0.033*\"particularly\" + '\n",
      "  '0.032*\"store\" + 0.027*\"mind\"'),\n",
      " (16,\n",
      "  '0.177*\"system\" + 0.085*\"bring\" + 0.074*\"ok\" + 0.051*\"soft\" + '\n",
      "  '0.045*\"recently\" + 0.045*\"cold\" + 0.034*\"item\" + 0.025*\"country\" + '\n",
      "  '0.023*\"adjustable_headrest\" + 0.007*\"shut\"'),\n",
      " (17,\n",
      "  '0.386*\"window\" + 0.113*\"auckland\" + 0.044*\"beverage\" + 0.027*\"wonderful\" + '\n",
      "  '0.022*\"somewhat\" + 0.018*\"load\" + 0.014*\"fa\" + 0.000*\"upper_deck\" + '\n",
      "  '0.000*\"touch\" + 0.000*\"wait\"'),\n",
      " (18,\n",
      "  '0.280*\"person\" + 0.118*\"charge\" + 0.082*\"spacious\" + 0.056*\"product\" + '\n",
      "  '0.052*\"decent\" + 0.038*\"future\" + 0.026*\"pad\" + 0.022*\"headr\" + '\n",
      "  '0.016*\"general\" + 0.012*\"star\"'),\n",
      " (19,\n",
      "  '0.194*\"premium\" + 0.167*\"extra\" + 0.155*\"pay\" + 0.072*\"economy\" + '\n",
      "  '0.071*\"upgrade\" + 0.045*\"money\" + 0.040*\"worth\" + 0.031*\"call\" + '\n",
      "  '0.024*\"international\" + 0.017*\"cost\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4900f123",
   "metadata": {},
   "source": [
    "## Compute Model Perplexity and Coherence Score\n",
    "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is. \n",
    "Coherence score is usually more helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1291c36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -11.086461784090512\n",
      "\n",
      "Coherence Score:  0.39898802535563826\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=reviews_lem, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc53d4",
   "metadata": {},
   "source": [
    "# Find BEST NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9684edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        print(\"-----------------------------------------\\n Building a model with: {} topics\".format(num_topics))\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        \n",
    "        print(\"Num Topics =\", num_topics, \" has Coherence Value of\", round(coherencemodel.get_coherence(), 4))\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7bf9576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      " Building a model with: 2 topics\n",
      "Num Topics = 2  has Coherence Value of 0.4061\n",
      "-----------------------------------------\n",
      " Building a model with: 4 topics\n",
      "Num Topics = 4  has Coherence Value of 0.4494\n",
      "-----------------------------------------\n",
      " Building a model with: 6 topics\n",
      "Num Topics = 6  has Coherence Value of 0.4472\n",
      "-----------------------------------------\n",
      " Building a model with: 8 topics\n",
      "Num Topics = 8  has Coherence Value of 0.4709\n"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=reviews_lem, start=2, limit=10, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8b3bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the score keeps increasing, but 8 seems like a fair amount of topics to deal with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b171d6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.126*\"economy\" + 0.087*\"premium\" + 0.032*\"extra\" + 0.031*\"upgrade\" + '\n",
      "  '0.020*\"money\" + 0.020*\"pay\" + 0.018*\"section\" + 0.018*\"worth\" + '\n",
      "  '0.017*\"class\" + 0.014*\"call\"'),\n",
      " (1,\n",
      "  '0.060*\"check\" + 0.025*\"boarding\" + 0.023*\"family\" + 0.021*\"unfortunately\" + '\n",
      "  '0.017*\"helpful\" + 0.017*\"smooth\" + 0.016*\"assign\" + 0.015*\"baggage\" + '\n",
      "  '0.013*\"ptv\" + 0.012*\"member\"'),\n",
      " (2,\n",
      "  '0.048*\"good\" + 0.038*\"comfortable\" + 0.034*\"economy\" + 0.033*\"legroom\" + '\n",
      "  '0.023*\"well\" + 0.022*\"screen\" + 0.022*\"recline\" + 0.020*\"aircraft\" + '\n",
      "  '0.020*\"use\" + 0.019*\"space\"'),\n",
      " (3,\n",
      "  '0.039*\"service\" + 0.032*\"class\" + 0.032*\"flight\" + 0.029*\"food\" + '\n",
      "  '0.024*\"business\" + 0.020*\"cabin\" + 0.018*\"airline\" + 0.017*\"offer\" + '\n",
      "  '0.017*\"emirate\" + 0.017*\"meal\"'),\n",
      " (4,\n",
      "  '0.058*\"system\" + 0.020*\"condition\" + 0.020*\"date\" + 0.020*\"similar\" + '\n",
      "  '0.017*\"soft\" + 0.016*\"touchscreen\" + 0.016*\"length\" + 0.015*\"reason\" + '\n",
      "  '0.015*\"acceptable\" + 0.013*\"outbound\"'),\n",
      " (5,\n",
      "  '0.042*\"laptop\" + 0.028*\"break\" + 0.027*\"pleasant\" + 0.022*\"clear\" + '\n",
      "  '0.022*\"later\" + 0.021*\"individual\" + 0.021*\"improvement\" + 0.015*\"truly\" + '\n",
      "  '0.014*\"computer\" + 0.014*\"socket\"'),\n",
      " (6,\n",
      "  '0.038*\"leg\" + 0.030*\"front\" + 0.025*\"row\" + 0.024*\"uncomfortable\" + '\n",
      "  '0.023*\"room\" + 0.021*\"make\" + 0.021*\"recline\" + 0.016*\"back\" + '\n",
      "  '0.015*\"flight\" + 0.012*\"bad\"'),\n",
      " (7,\n",
      "  '0.059*\"flight\" + 0.033*\"fly\" + 0.024*\"plane\" + 0.023*\"hour\" + 0.020*\"get\" + '\n",
      "  '0.019*\"airline\" + 0.015*\"passenger\" + 0.013*\"small\" + 0.012*\"people\" + '\n",
      "  '0.011*\"go\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "83f17d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>flight, fly, plane, hour, get, airline, passen...</td>\n",
       "      <td>newer aircraft leg room awful seat comfortable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>flight, fly, plane, hour, get, airline, passen...</td>\n",
       "      <td>check easy boarding zone think paid check kg l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>good, comfortable, economy, legroom, well, scr...</td>\n",
       "      <td>solid experience start finish especially given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>flight, fly, plane, hour, get, airline, passen...</td>\n",
       "      <td>discovered upon boarding four year old allocat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>good, comfortable, economy, legroom, well, scr...</td>\n",
       "      <td>got seat near emergency exit different standar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>good, comfortable, economy, legroom, well, scr...</td>\n",
       "      <td>seat pitch tight still survivable hour flight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5015</td>\n",
       "      <td>flight, fly, plane, hour, get, airline, passen...</td>\n",
       "      <td>seat uncomfortable space seat poor hard time s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.4804</td>\n",
       "      <td>leg, front, row, uncomfortable, room, make, re...</td>\n",
       "      <td>good choose airasia flight le hour distance se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>leg, front, row, uncomfortable, room, make, re...</td>\n",
       "      <td>allocated seat airasia flight ak nov kuala ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>leg, front, row, uncomfortable, room, make, re...</td>\n",
       "      <td>seat recline notice great hate someone tilt se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             7.0              0.3508   \n",
       "1            1             7.0              0.5420   \n",
       "2            2             2.0              0.3065   \n",
       "3            3             7.0              0.4050   \n",
       "4            4             2.0              0.3212   \n",
       "5            5             2.0              0.3654   \n",
       "6            6             7.0              0.5015   \n",
       "7            7             6.0              0.4804   \n",
       "8            8             6.0              0.2576   \n",
       "9            9             6.0              0.3411   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  flight, fly, plane, hour, get, airline, passen...   \n",
       "1  flight, fly, plane, hour, get, airline, passen...   \n",
       "2  good, comfortable, economy, legroom, well, scr...   \n",
       "3  flight, fly, plane, hour, get, airline, passen...   \n",
       "4  good, comfortable, economy, legroom, well, scr...   \n",
       "5  good, comfortable, economy, legroom, well, scr...   \n",
       "6  flight, fly, plane, hour, get, airline, passen...   \n",
       "7  leg, front, row, uncomfortable, room, make, re...   \n",
       "8  leg, front, row, uncomfortable, room, make, re...   \n",
       "9  leg, front, row, uncomfortable, room, make, re...   \n",
       "\n",
       "                                                Text  \n",
       "0  newer aircraft leg room awful seat comfortable...  \n",
       "1  check easy boarding zone think paid check kg l...  \n",
       "2  solid experience start finish especially given...  \n",
       "3  discovered upon boarding four year old allocat...  \n",
       "4  got seat near emergency exit different standar...  \n",
       "5  seat pitch tight still survivable hour flight ...  \n",
       "6  seat uncomfortable space seat poor hard time s...  \n",
       "7  good choose airasia flight le hour distance se...  \n",
       "8  allocated seat airasia flight ak nov kuala ban...  \n",
       "9  seat recline notice great hate someone tilt se...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find dominant topic in each sentence\n",
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=reviews):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row[0], key=lambda x: x[1], reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "# for row in optimal_model[corpus]:\n",
    "#     print(row[0][1])\n",
    "#     break\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=reviews)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "14636b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.index = df_dominant_topic.Document_No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e6f3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic = df_dominant_topic.drop(\"Document_No\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "684cca1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Document_No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3508</td>\n",
       "      <td>flight, fly, plane, hour, get, airline, passen...</td>\n",
       "      <td>newer aircraft leg room awful seat comfortable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>flight, fly, plane, hour, get, airline, passen...</td>\n",
       "      <td>check easy boarding zone think paid check kg l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>good, comfortable, economy, legroom, well, scr...</td>\n",
       "      <td>solid experience start finish especially given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>flight, fly, plane, hour, get, airline, passen...</td>\n",
       "      <td>discovered upon boarding four year old allocat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>good, comfortable, economy, legroom, well, scr...</td>\n",
       "      <td>got seat near emergency exit different standar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "Document_No                                       \n",
       "0                       7.0              0.3508   \n",
       "1                       7.0              0.5420   \n",
       "2                       2.0              0.3065   \n",
       "3                       7.0              0.4050   \n",
       "4                       2.0              0.3212   \n",
       "\n",
       "                                                      Keywords  \\\n",
       "Document_No                                                      \n",
       "0            flight, fly, plane, hour, get, airline, passen...   \n",
       "1            flight, fly, plane, hour, get, airline, passen...   \n",
       "2            good, comfortable, economy, legroom, well, scr...   \n",
       "3            flight, fly, plane, hour, get, airline, passen...   \n",
       "4            good, comfortable, economy, legroom, well, scr...   \n",
       "\n",
       "                                                          Text  \n",
       "Document_No                                                     \n",
       "0            newer aircraft leg room awful seat comfortable...  \n",
       "1            check easy boarding zone think paid check kg l...  \n",
       "2            solid experience start finish especially given...  \n",
       "3            discovered upon boarding four year old allocat...  \n",
       "4            got seat near emergency exit different standar...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7df20769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2594"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9365b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
